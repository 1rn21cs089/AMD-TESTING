{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d81ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa079c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text = \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence \\\n",
    "concerned with the interactions between computers and human language. In particular, it focuses on programming \\\n",
    "computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59f9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams and their frequency distribution\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq_dist = FreqDist(bigrams)\n",
    "\n",
    "# Prepare the dataset for training\n",
    "train_data, padded_sents = padded_everygram_pipeline(2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8467b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram model\n",
    "model = MLE(2)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501c6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is natural language processing?\n",
      "A: is a l y z e r t e r\n",
      "\n",
      "Q: How does artificial intelligence relate to linguistics?\n",
      "A: linguistics e n g u i n c t i\n",
      "\n",
      "Q: Can computers understand human language?\n",
      "A: ? g </s> </s> </s> r </s> </s> e s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, num_words, seed_word):\n",
    "    sentence = [seed_word]\n",
    "    for _ in range(num_words - 1):\n",
    "        next_word = model.generate(1, text_seed=sentence)\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example questions to the model\n",
    "questions = [\n",
    "    \"What is natural language processing?\",\n",
    "    \"How does artificial intelligence relate to linguistics?\",\n",
    "    \"Can computers understand human language?\",\n",
    "]\n",
    "\n",
    "# Generate answers for the questions\n",
    "for question in questions:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    seed_word = choice(tokens)\n",
    "    generated_sentence = generate_sentence(model, 10, seed_word)\n",
    "    print(f\"Q: {question}\\nA: {generated_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3363bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudagpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
